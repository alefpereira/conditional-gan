{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recriação de dígitos utilizando Conditional GAN na base MNIST\n",
    "By Alef Pereira _<<apn2@icomp.ufam.edu.br>>_\n",
    "\n",
    "_(3) abstract;_\n",
    "\n",
    "## Introdução\n",
    " \n",
    "Generative Adversarial Networks, ou GANs foram introduzidas em 2014 como uma solução para o treinamento de modelos geradores. Desde lá o método vem sendo utilizado em diversas aplicações como na geração de dígitos, rostos humanos, imagens de animais ou plantas, paisagens e até na criação de arte.\n",
    "\n",
    "Entretanto, uma característica notável de GANs é que seu treinamento é extremamente difícil, pois, para o sucesso do treino, deve haver um equilíbrio entre o componente discriminador e o gerador. Por esse motivo esse método é bastante estudado, com isso novas estratégias de treino e variação do modelo foram criadas com o objetivo de tornar essas redes mais robustas, como DCGAN e BEGAN que são abordagens modernas com resultados mais estáveis.\n",
    "\n",
    "Este trabalho falará um pouco sobre _Conditional GANs_, ou GANs condicionadas, que foi introduzida também em 2014 logo após a publicação de Goodfelow. O princípio dessa rede é condicionar o aprendizado do modelo com alguma informação referente ao problema ou a saída esperada. O objetivo é direcionar o aprendizado do método. No artigo, os autores apresentam o condicionamento de uma GAN incluindo o rótulo das instâncias a entrada tanto para o discriminador quanto para o gerador.\n",
    "\n",
    "Partindo do princípio da rede geradora condicional, neste trabalho será experimentado um modelo capaz de recriar dígitos a partir de entradas parcialmente danificadas. A ideia é incluir a entrada do gerador, imagens da MNIST com ruído, por exemplo, a desativação de pixels, ao envés de entregar vetores aleatórios, e com isso verificar a capacidade do modelo de gerarem bons resultados sendo condicionadas a entradas ruidosas.\n",
    "\n",
    "Problemas que podem se beneficiar dessa abordagem incluem OCR, por exemplo, restauração de imagens danificadas, ou até mesmo em recuperação de dados como recriação de pacotes de dados quando há perda de informação durante transmissão.\n",
    "\n",
    "A base de dados utilizada será a MNIST, uma coleção de dígitos manuscritos, com 60 mil instâncias de treino e 10 mil instâncias de teste criada por Yann LeCun et al. em 1998. Essa coleção vem sendo amplamente utilizada em diversos banchmarks de métodos de aprendizagem de máquina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhos Relacionados\n",
    "\n",
    "### GAN\n",
    "\n",
    "### GAN Condicionada\n",
    "\n",
    "### Inpainting\n",
    "\n",
    "## Descrição do Método\n",
    "\n",
    "Descrição da arquitetura da rede.\n",
    "\n",
    "Como incorporar os rótulos na entrada de G e D. one hot vectors. tf.concat\n",
    "\n",
    "como incorporar os dados com ruído na entrada do gerador.\n",
    "\n",
    "## Resultados Preliminares\n",
    "A implementação da CGAN é essencialmente a de Kristiadi, disponibilizada em 2017.\n",
    "\n",
    "Outro teste executado foi utilizando uma implementação da rede condicional descrita no trabalho de CGAN.\n",
    "\n",
    "Resultados parciais.\n",
    "\n",
    "![CGAN_1](out_5randomT1/123_1.png)\n",
    "![CGAN_4](out_5randomT1/122_4.png)\n",
    "![CGAN_5](out_5randomT1/124_5.png)\n",
    "\n",
    "## Conclusões Preliminares\n",
    "Comparar com outros métodos (baseline)\n",
    "Esse experimento foi realizado apenas como prova de conceito.\n",
    "Utilizando essa abordagem é possível fazer inpainting.\n",
    "\n",
    "## Trabalhos Futuros\n",
    "Utilizar CGAN alimentado por um modelo matemático*(procurar) e fazer uma rede que além de resolver equações simples, gera dígitos artificiais para representar o resultado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "[[Mark]](https://papers.nips.cc/paper/4686-image-denoising-and-inpainting-with-deep-neural-networks) Xie J., Xu L., Chen E. Image Denoising and Inpainting with Deep Neural Networks. NIPS 2012.\n",
    "\n",
    "[[Mark]](https://arxiv.org/abs/1701.00160) Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. NIPS 2014.\n",
    "\n",
    "[[1]](https://arxiv.org/abs/1703.10717) Berthelot, Schumm and Metz. BEGAN: Boundary Equilibrium Generative Adversarial Networks. arXiv preprint, 2017.\n",
    "\n",
    "[[Mark]](https://arxiv.org/abs/1411.1784) Mirza, M., Osindero, S. Conditional Generative Adversarial Nets. arXiv preprint, November 2014.\n",
    "\n",
    "[[Mark]](https://arxiv.org/abs/1511.06434) Radford, A., Metz L., Chintala S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv preprint, November 2015.\n",
    "\n",
    "[[Mark]](https://github.com/wiseodd/generative-models) Kristiadi A. Generative Models. 2017. GitHub repository: <https://github.com/wiseodd/generative-models>.\n",
    "\n",
    "[[Mark]](https://github.com/jonbruner/generative-adversarial-networks) Bruner J. Introduction to generative adversarial networks. 2017. GitHub repository: <https://github.com/jonbruner/generative-adversarial-networks>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
